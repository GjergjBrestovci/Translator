{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da3217ca",
   "metadata": {},
   "source": [
    "# Albanian Translator Training (Colab)\n",
    "\n",
    "This notebook runs the existing project training pipeline on Colab GPU and saves everything to Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "343aa34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive mount failed, falling back to local /content storage.\n",
      "Failed to issue request POST https://colab.research.google.com/tun/m/credentials-propagation/m-s-28it4rnpehd4u?authtype=dfs_ephemeral&version=2&dryrun=false&propagate=true&record=false&authuser=0&authuser=0: Bad Request\n",
      "Response body: \n",
      "<!DOCTYPE html>\n",
      "<html lang=en>\n",
      "  <meta charset=utf-8>\n",
      "  <meta name=viewport content=\"initial-scale=1, minimum-scale=1, width=device-width\">\n",
      "  <title>Error 400 (Bad Request)!!1</title>\n",
      "  <style>\n",
      "    *{margin:0;padding:0}html,code{font:15px/22px arial,sans-serif}html{background:#fff;color:#222;padding:15px}body{margin:7% auto 0;max-width:390px;min-height:180px;padding:30px 0 15px}* > body{background:url(//www.google.com/images/errors/robot.png) 100% 5px no-repeat;padding-right:205px}p{margin:11px 0 22px;overflow:hidden}ins{color:#777;text-decoration:none}a img{border:0}@media screen and (max-width:772px){body{background:none;margin-top:0;max-width:none;padding-right:0}}#logo{background:url(//www.google.com/images/logos/errorpage/error_logo-150x54.png) no-repeat;margin-left:-5px}@media only screen and (min-resolution:192dpi){#logo{background:url(//www.google.com/images/logos/errorpage/error_logo-150x54-2x.png) no-repeat 0% 0%/100% 100%;-moz-border-image:url(//www.google.com/images/logos/errorpage/error_logo-150x54-2x.png) 0}}@media only screen and (-webkit-min-device-pixel-ratio:2){#logo{background:url(//www.google.com/images/logos/errorpage/error_logo-150x54-2x.png) no-repeat;-webkit-background-size:100% 100%}}#logo{display:inline-block;height:54px;width:150px}\n",
      "  </style>\n",
      "  <a href=//www.google.com/><span id=logo aria-label=Google></span></a>\n",
      "  <p><b>400.</b> <ins>That’s an error.</ins>\n",
      "  <p>  <ins>That’s all we know.</ins>\n",
      "\n",
      "PROJECT_DIR: /content/Translator\n",
      "DATA_DIR: data/alb_en\n",
      "Persistence: Ephemeral /content\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "USE_DRIVE = True\n",
    "PROJECT_DIR = \"/content/Translator\"\n",
    "DATA_DIR = \"data/alb_en\"\n",
    "\n",
    "if USE_DRIVE:\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        PROJECT_DIR = \"/content/drive/MyDrive/Translator\"\n",
    "    except Exception as error:\n",
    "        print(\"Drive mount failed, falling back to local /content storage.\")\n",
    "        print(error)\n",
    "\n",
    "Path(PROJECT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "print(\"PROJECT_DIR:\", PROJECT_DIR)\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"Persistence:\", \"Drive\" if PROJECT_DIR.startswith('/content/drive') else \"Ephemeral /content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c843683",
   "metadata": {},
   "source": [
    "### Storage mode\n",
    "\n",
    "- Notebook is now set to **Google Drive by default** (`USE_DRIVE = True`) so checkpoints persist.\n",
    "- If Drive mount fails, it falls back to local `/content/Translator` (temporary storage).\n",
    "- Keep `DATA_DIR = \"data/alb_en\"` unless you intentionally change dataset location."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c07da3",
   "metadata": {},
   "source": [
    "## Clone or update project in Drive\\n\n",
    "Set your repo URL below, then run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce4131a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning repo...\n",
      "Project ready at: /content/Translator\n",
      "Found training script: /content/Translator/scripts/train_albanian_to_english.py\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "REPO_URL = \"https://github.com/GjergjBrestovci/Translator.git\"  # set this first\n",
    "\n",
    "if not os.path.exists(PROJECT_DIR):\n",
    "    os.makedirs(PROJECT_DIR, exist_ok=True)\n",
    "\n",
    "if os.path.exists(os.path.join(PROJECT_DIR, \".git\")):\n",
    "    print(\"Repo exists, pulling latest...\")\n",
    "    subprocess.run([\"git\", \"-C\", PROJECT_DIR, \"pull\"], check=False)\n",
    "else:\n",
    "    if \"<your-user>\" in REPO_URL or \"<your-repo>\" in REPO_URL:\n",
    "        raise ValueError(\"Set REPO_URL to your actual GitHub repository before continuing.\")\n",
    "    print(\"Cloning repo...\")\n",
    "    subprocess.run([\"git\", \"clone\", REPO_URL, PROJECT_DIR], check=True)\n",
    "\n",
    "script_path = os.path.join(PROJECT_DIR, \"scripts\", \"train_albanian_to_english.py\")\n",
    "if not os.path.exists(script_path):\n",
    "    raise FileNotFoundError(\n",
    "        f\"Missing {script_path}. Confirm REPO_URL points to this Translator project.\"\n",
    "    )\n",
    "\n",
    "print(\"Project ready at:\", PROJECT_DIR)\n",
    "print(\"Found training script:\", script_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "822d964e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Translator\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-26.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-26.0.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.1.2\n",
      "    Uninstalling pip-24.1.2:\n",
      "      Successfully uninstalled pip-24.1.2\n",
      "Successfully installed pip-26.0.1\n",
      "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (4.0.0)\n",
      "Requirement already satisfied: transformers>=4.48.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (5.0.0)\n",
      "Collecting evaluate>=0.4.0 (from -r requirements.txt (line 3))\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting sacrebleu>=2.4.0 (from -r requirements.txt (line 4))\n",
      "  Downloading sacrebleu-2.6.0-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (0.2.1)\n",
      "Requirement already satisfied: accelerate>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (1.12.0)\n",
      "Requirement already satisfied: torch>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (2.10.0+cpu)\n",
      "Requirement already satisfied: tqdm>=4.66.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (4.67.3)\n",
      "Requirement already satisfied: fastapi>=0.115.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (0.129.0)\n",
      "Requirement already satisfied: uvicorn>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.34.0->-r requirements.txt (line 10)) (0.41.0)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (2.12.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->-r requirements.txt (line 1)) (3.24.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->-r requirements.txt (line 1)) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->-r requirements.txt (line 1)) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->-r requirements.txt (line 1)) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->-r requirements.txt (line 1)) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->-r requirements.txt (line 1)) (2.32.4)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->-r requirements.txt (line 1)) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->-r requirements.txt (line 1)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->-r requirements.txt (line 1)) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->-r requirements.txt (line 1)) (1.4.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->-r requirements.txt (line 1)) (26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->-r requirements.txt (line 1)) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->-r requirements.txt (line 1)) (3.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.48.0->-r requirements.txt (line 2)) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.48.0->-r requirements.txt (line 2)) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers>=4.48.0->-r requirements.txt (line 2)) (0.24.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.48.0->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets>=3.0.0->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets>=3.0.0->-r requirements.txt (line 1)) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets>=3.0.0->-r requirements.txt (line 1)) (1.5.4)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets>=3.0.0->-r requirements.txt (line 1)) (4.15.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets>=3.0.0->-r requirements.txt (line 1)) (4.12.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets>=3.0.0->-r requirements.txt (line 1)) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets>=3.0.0->-r requirements.txt (line 1)) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets>=3.0.0->-r requirements.txt (line 1)) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets>=3.0.0->-r requirements.txt (line 1)) (0.16.0)\n",
      "Collecting portalocker (from sacrebleu>=2.4.0->-r requirements.txt (line 4))\n",
      "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu>=2.4.0->-r requirements.txt (line 4)) (0.9.0)\n",
      "Collecting colorama (from sacrebleu>=2.4.0->-r requirements.txt (line 4))\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu>=2.4.0->-r requirements.txt (line 4)) (6.0.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.0.0->-r requirements.txt (line 6)) (5.9.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.0->-r requirements.txt (line 7)) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.0->-r requirements.txt (line 7)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.0->-r requirements.txt (line 7)) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.0->-r requirements.txt (line 7)) (3.1.6)\n",
      "Requirement already satisfied: starlette<1.0.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.115.0->-r requirements.txt (line 9)) (0.52.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.115.0->-r requirements.txt (line 9)) (0.4.2)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.115.0->-r requirements.txt (line 9)) (0.0.4)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.34.0->uvicorn[standard]>=0.34.0->-r requirements.txt (line 10)) (8.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->-r requirements.txt (line 11)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->-r requirements.txt (line 11)) (2.41.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->-r requirements.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->-r requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->-r requirements.txt (line 1)) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->-r requirements.txt (line 1)) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->-r requirements.txt (line 1)) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->-r requirements.txt (line 1)) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->-r requirements.txt (line 1)) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->-r requirements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.2.0->-r requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.34.0->-r requirements.txt (line 10)) (0.7.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.34.0->-r requirements.txt (line 10)) (1.2.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.34.0->-r requirements.txt (line 10)) (0.22.1)\n",
      "Requirement already satisfied: watchfiles>=0.20 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.34.0->-r requirements.txt (line 10)) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.34.0->-r requirements.txt (line 10)) (15.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.2.0->-r requirements.txt (line 7)) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->-r requirements.txt (line 1)) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers>=4.48.0->-r requirements.txt (line 2)) (0.24.0)\n",
      "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers>=4.48.0->-r requirements.txt (line 2)) (13.9.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers>=4.48.0->-r requirements.txt (line 2)) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers>=4.48.0->-r requirements.txt (line 2)) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->transformers>=4.48.0->-r requirements.txt (line 2)) (0.1.2)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "Downloading sacrebleu-2.6.0-py3-none-any.whl (100 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: portalocker, colorama, sacrebleu, evaluate\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [evaluate]3/4\u001b[0m [evaluate]\n",
      "\u001b[1A\u001b[2KSuccessfully installed colorama-0.4.6 evaluate-0.4.6 portalocker-3.2.0 sacrebleu-2.6.0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%cd $PROJECT_DIR\n",
    "!test -f scripts/train_albanian_to_english.py || (echo \"Training script missing. Run the repo setup cell first.\" && exit 1)\n",
    "%pip install -U pip\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb163b4",
   "metadata": {},
   "source": [
    "## Optional: rebuild/expand dataset (rows-api stable mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d078ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Translator\n",
      "Streaming subset: aln_Latn\n",
      "aln_Latn: 563it [00:02, 199.08it/s]\n",
      "Streaming subset: als_Latn\n",
      "als_Latn: 50000it [15:14, 54.65it/s] \n",
      "Dataset prepared:\n",
      "{\n",
      "  \"subsets\": [\n",
      "    \"aln_Latn\",\n",
      "    \"als_Latn\"\n",
      "  ],\n",
      "  \"num_total\": 50557,\n",
      "  \"num_train\": 49545,\n",
      "  \"num_validation\": 505,\n",
      "  \"num_test\": 507,\n",
      "  \"data_backend\": \"rows-api\",\n",
      "  \"max_samples_per_subset\": 50000,\n",
      "  \"min_source_chars\": 20,\n",
      "  \"drop_early_stop\": true,\n",
      "  \"seed\": 42\n",
      "}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%cd $PROJECT_DIR\n",
    "!PYTHONUNBUFFERED=1 python scripts/prepare_dataset.py \\\n",
    "  --subsets aln_Latn als_Latn \\\n",
    "  --output-dir $DATA_DIR \\\n",
    "  --data-backend rows-api \\\n",
    "  --max-samples-per-subset 50000 \\\n",
    "  --rows-api-page-size 100 \\\n",
    "  --rows-api-retries 8 \\\n",
    "  --rows-api-retry-wait-seconds 2.0 \\\n",
    "  --rows-api-request-interval-seconds 0.15 \\\n",
    "  --drop-early-stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619938f5",
   "metadata": {},
   "source": [
    "## Train (cool/stable defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6739162d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (ipython-input-2412385832.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-2412385832.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    --data-dir $DATA_DIR \\\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%cd $PROJECT_DIR\n",
    "\n",
    "!PYTHONUNBUFFERED=1 OMP_NUM_THREADS=2 TOKENIZERS_PARALLELISM=false python scripts/train_albanian_to_english.py \\\n",
    "\n",
    "  --data-dir $DATA_DIR \\\n",
    "\n",
    "  --model-name Helsinki-NLP/opus-mt-sq-en \\\n",
    "\n",
    "  --output-dir outputs/opusmt-alb-en-colab \\\n",
    "\n",
    "  --num-train-epochs 1.0 \\\n",
    "\n",
    "  --per-device-train-batch-size 4 \\\n",
    "\n",
    "  --per-device-eval-batch-size 4 \\\n",
    "\n",
    "  --gradient-accumulation-steps 4 \\\n",
    "\n",
    "  --eval-steps 1500 \\\n",
    "\n",
    "  --save-steps 1500 \\\n",
    "\n",
    "  --logging-steps 50 \\\n",
    "\n",
    "  --fp16 \\\n",
    "\n",
    "  --generation-max-length 192 \\\n",
    "\n",
    "  --generation-num-beams 1 \\\n",
    "\n",
    "  --dataloader-num-workers 0 \\\n",
    "\n",
    "  --no-filter-noisy-pairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1795513b",
   "metadata": {},
   "source": [
    "## Resume after disconnect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acba664c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Translator\n",
      "usage: train_albanian_to_english.py [-h] [--data-dir DATA_DIR]\n",
      "                                    [--model-name MODEL_NAME]\n",
      "                                    [--output-dir OUTPUT_DIR]\n",
      "                                    [--max-source-length MAX_SOURCE_LENGTH]\n",
      "                                    [--max-target-length MAX_TARGET_LENGTH]\n",
      "                                    [--per-device-train-batch-size PER_DEVICE_TRAIN_BATCH_SIZE]\n",
      "                                    [--per-device-eval-batch-size PER_DEVICE_EVAL_BATCH_SIZE]\n",
      "                                    [--learning-rate LEARNING_RATE]\n",
      "                                    [--num-train-epochs NUM_TRAIN_EPOCHS]\n",
      "                                    [--weight-decay WEIGHT_DECAY]\n",
      "                                    [--logging-steps LOGGING_STEPS]\n",
      "                                    [--eval-steps EVAL_STEPS]\n",
      "                                    [--save-steps SAVE_STEPS] [--seed SEED]\n",
      "                                    [--gradient-accumulation-steps GRADIENT_ACCUMULATION_STEPS]\n",
      "                                    [--generation-max-length GENERATION_MAX_LENGTH]\n",
      "                                    [--generation-num-beams GENERATION_NUM_BEAMS]\n",
      "                                    [--dataloader-num-workers DATALOADER_NUM_WORKERS]\n",
      "                                    [--eval-accumulation-steps EVAL_ACCUMULATION_STEPS]\n",
      "                                    [--filter-noisy-pairs | --no-filter-noisy-pairs]\n",
      "                                    [--min-source-chars MIN_SOURCE_CHARS]\n",
      "                                    [--min-target-chars MIN_TARGET_CHARS]\n",
      "                                    [--max-source-chars MAX_SOURCE_CHARS]\n",
      "                                    [--max-target-chars MAX_TARGET_CHARS]\n",
      "                                    [--min-length-ratio MIN_LENGTH_RATIO]\n",
      "                                    [--max-length-ratio MAX_LENGTH_RATIO]\n",
      "                                    [--fp16]\n",
      "train_albanian_to_english.py: error: unrecognized arguments: --resume-from-checkpoint outputs/opusmt-alb-en-colab/checkpoint-1500\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import subprocess\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(PROJECT_DIR)\n",
    "\n",
    "script = os.path.join(PROJECT_DIR, \"scripts\", \"train_albanian_to_english.py\")\n",
    "\n",
    "checkpoint_path = \"outputs/opusmt-alb-en-colab/checkpoint-1500\"\n",
    "\n",
    "\n",
    "\n",
    "base_cmd = [\n",
    "\n",
    "    \"python\",\n",
    "\n",
    "    script,\n",
    "\n",
    "    \"--data-dir\", DATA_DIR,\n",
    "\n",
    "    \"--model-name\", \"Helsinki-NLP/opus-mt-sq-en\",\n",
    "\n",
    "    \"--output-dir\", \"outputs/opusmt-alb-en-colab\",\n",
    "\n",
    "    \"--num-train-epochs\", \"1.0\",\n",
    "\n",
    "    \"--per-device-train-batch-size\", \"4\",\n",
    "\n",
    "    \"--per-device-eval-batch-size\", \"4\",\n",
    "\n",
    "    \"--gradient-accumulation-steps\", \"4\",\n",
    "\n",
    "    \"--eval-steps\", \"1500\",\n",
    "\n",
    "    \"--save-steps\", \"1500\",\n",
    "\n",
    "    \"--logging-steps\", \"50\",\n",
    "\n",
    "    \"--fp16\",\n",
    "\n",
    "    \"--generation-max-length\", \"192\",\n",
    "\n",
    "    \"--generation-num-beams\", \"1\",\n",
    "\n",
    "    \"--dataloader-num-workers\", \"0\",\n",
    "\n",
    "    \"--no-filter-noisy-pairs\",\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "env = os.environ.copy()\n",
    "\n",
    "env[\"PYTHONUNBUFFERED\"] = \"1\"\n",
    "\n",
    "env[\"OMP_NUM_THREADS\"] = \"2\"\n",
    "\n",
    "env[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "\n",
    "help_output = subprocess.run(\n",
    "\n",
    "    [\"python\", script, \"--help\"],\n",
    "\n",
    "    env=env,\n",
    "\n",
    "    capture_output=True,\n",
    "\n",
    "    text=True,\n",
    "\n",
    ")\n",
    "\n",
    "resume_supported = \"--resume-from-checkpoint\" in help_output.stdout\n",
    "\n",
    "\n",
    "\n",
    "cmd = list(base_cmd)\n",
    "\n",
    "if resume_supported and os.path.isdir(checkpoint_path):\n",
    "\n",
    "    cmd.extend([\"--resume-from-checkpoint\", checkpoint_path])\n",
    "\n",
    "    print(f\"Resuming from: {checkpoint_path}\")\n",
    "\n",
    "elif not resume_supported:\n",
    "\n",
    "    print(\"Resume flag not supported by current script version; running without resume.\")\n",
    "\n",
    "else:\n",
    "\n",
    "    print(f\"Checkpoint not found at {checkpoint_path}; running without resume.\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Running:\", \" \".join(cmd))\n",
    "\n",
    "subprocess.run(cmd, env=env, check=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
